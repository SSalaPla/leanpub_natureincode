# 6. Natural Selection: The Best Idea Anyone’s Ever Had

Natural selection is often equated with evolution. But as you now know, evolution is simply the change in allele frequencies. Natural selection is just one of the forces affecting these allele frequencies. Thus, natural selection is not evolution - rather, natural selection is a cause of evolution.

What sets natural selection apart from the other forces that shape evolution (drift, mutation, and migration) is that it is the only force capable of producing adaptive traits. An adaptive trait is a trait of an individual - such as the color of a flower, the shape of a hand, the efficiency of a lung - that makes the individual well adapted to the environment it lives in. But what does “well adapted“ mean? It simply means that all else being equal, the individual is more likely to survive and produce offspring than it would without that specific trait.

Some of the most visually stunning examples of adaptation are those of animal mimicry. Mimicry is the imitation of another species. If you have a hard time seeing the leaf katydid (an insect) in the image below, it’s because of the spectacular visual imitation of the plant that it rests on. In nature, you would probably have missed it entirely - just like most birds and other predators who would love nothing more than to eat the insect for lunch. 

![](images/ch_6_mimicry.jpg)

(Photo by [Geoff Gallice](http://bit.ly/1vU1Y0W)). Darwin’s insight was the following. In a world where natural resources are limited, there will be a struggle for survival and reproduction. Those individuals who are better adapted to survive, and to produce many offspring individuals, will contribute more offspring individuals to the next generation than those who are less well adapted. Because the offspring individuals inherit the traits that made their parents better adapted, those traits will increase in frequency over the generations. 

We have so far in this booked avoided the issue of the struggle for survival and reproduction. In all of our models so far, we have assumed that in terms of the probabilities of making it to the next generation, all alleles, and all genotypes, are equal. *Natural selection occurs when that assumption is not true anymore.*

Another way of saying that all alleles and genotypes are equal with respect to making it into the next generation is to say that they have the same *evolutionary (or darwinian) fitness*. This is a key concept in evolutionary biology. Evolutionary fitness is the ability to survive and reproduce. Notice that fitness is not an absolute value, but rather a relative one. If a certain allele has a higher fitness than other alleles, that means that it is more likely than the other alleles to survive and make copies of itself (of course, alleles don’t survive themselves, but the individuals carrying the alleles do). As a consequence of this, the allele is expected to increase in frequency in the population. This is evolution by natural selection. It is *evolution* because the allele frequencies change; and it is *by natural selection* because the allele frequencies change as a consequence of a higher fitness.

What we have assumed so far throughout the book is that all alleles and genotypes have the same fitness - without actually invoking the concept of fitness. Because all alleles or genotypes had the same fitness, they were *selectively neutral*. As we have now seen many times, just because alleles are selectively neutral does *not* mean that we don’t get evolution as an outcome! Finite population size, mutations, and migration alone will lead to evolution, even if all alleles have the same fitness and are thus selectively neutral. The only difference when alleles do have differential fitness (i.e. not all of them have the exact same fitness) is that evolution becomes predictable in one regard: the alleles with higher fitness will become more common, and the ones with lower fitness will become less common. That’s very different from the situation when alleles are selectively neutral - which alleles will go to fixation, and which ones will be lost, is completely due to chance, and thus impossible to predict.

I want to give you a visual example straight away. Remember in chapter 3, when we ran multiple simulations of genetic drift? We had our simple one locus, two alleles model, and we initiated the population at `p = 0.5`, which is to say half of the alleles were A1 and the other half A2, and then we observed the change of allele frequencies over time.

For a population of size `N = 2,000`, the typical graph for ten simulations looked something like this:

{width=90%}
![](images/ch_3_drift_multi_population_N_2000.png)

In some simulations, the frequency of A1 would go up, in others, it would go down, and we learned that in about half of simulations, A1 would eventually go to fixation, and in the other half, A2 would eventually go to fixation.

The crucial function in the code underlying this graph was the following:

~~~~~~~~
function next_generation(simulation_data) {
  var draws = 2 * N;
  var A1 = 0;
  var A2 = 0;
  for (var i = 0; i < draws; i = i + 1) {
    if (Math.random() <= p) {
      A1 = A1 + 1;
    }
    else {
      A2 = A2 + 1;
    }
  }
  p = A1/draws;
  simulation_data.push(p);
}
~~~~~~~~

As you may recall, we are picking alleles randomly to produce the next generation, and we do this simply in accordance to their frequencies - allele A1 is picked with probability `p` (i.e. the  frequency of A1), and allele A2 is picked with probability `1-p` (i.e. the frequency of A2).

Now let’s introduce a seemingly minor change. Let’s the change this line in the function:

~~~~~~~~
if (Math.random() <= p) {
~~~~~~~~

to this 

~~~~~~~~
if (Math.random() <= p*1.01) {
~~~~~~~~

What this means is that we’re not picking allele A1 with a probability that corresponds to its frequency anymore. Rather, we are picking it with a probability that is a mere 1% higher than its frequency. Consequently, A2 is picked with a probability that is slightly less than its frequency.

Now let’s take a look at the outcome with this minor change in the code:

{width=90%}
![](images/ch_6_selection_multi_population_N_2000.png)

Quite a different outcome! What is happening here? Natural selection, that’s what’s happening!

By increasing the probability of picking allele A1 to make it into the next generation from `p` to `1.01*p`, we are giving the allele a slight selective benefit over allele A2. In other words, allele A1 has a slightly higher fitness than allele A2.

This example has hopefully brought home the main point about fitness, natural selection, and its consequences. Because the example is borrowed from chapter 3, it uses a finite population size, and thus the effects of drift are still acting. Indeed, in real populations, both drift and natural selection are generally acting at the same time, and depending on the situation, one force can be much stronger than the other. In the example above, the dynamics were dominated by the force of natural selection. However, you can still see that the lines zigzag a little bit - that's the force of chance that's still acting there.

This is important in the beginning, when a new mutation arises - even one that has a higher fitness than its competing alleles. We can take the code of the example above, and start the simulation at `p=0.01`, rather than at `p=0.5`. To do that, change the first line in the `simulation()` function from 

~~~~~~~~
p = 0.5;
~~~~~~~~

to

~~~~~~~~
p = 0.01;
~~~~~~~~ 

In order to see the dynamics in full, you will also need to increase the number of generations by setting `generations` to `1000`:

~~~~~~~~
var generations = 1000;
~~~~~~~~

When you run this code, you'll see the following dynamic play out:

{width=90%}
![](images/ch_6_selection_multi_population_N_2000_p_001.png)

As you can see, the allele will go to fixation in only a fraction of the simulations. In the other simulations, genetic drift has pushed it to extinction *before* natural selection could sweep the allele to fixation. And consider that in reality, mutations don't start at *p=0.01*, but at the generally lower frequency of {$$}p=\frac{1}{2N}{/$$}, which means that the initial hump to overcome is even higher. It's sobering to think about all the highly adaptive mutations that have occurred in the history of life, but that have never made it across the threshold where natural selection could take over and bring them to fixation.

With that in mind, in this chapter, we are going to investigate the effects of natural selection in isolation - that is, in populations of infinite size, where drift does not come into play at all.

We are going to start by formalizing the concept of fitness. We have mentioned above that an allele, or a genotype, has a fitness. Mathematically, we can capture the genotypic fitness as follows. We can simply assign the following fitness values to the three possible genotypes:

{width="wide"}
|  |A1A1 |A1A2 |A2A2|
|----------:|:------------:|:------------:|:-------------:|
| Fitness:  |{$$}w_{11}{/$$}|{$$}w_{12}{/$$}|{$$}w_{22}{/$$}|

Let us assume, for simplicity, that the genotypes are at Hardy-Weinberg equilibrium. That is, their frequencies are:

{width="wide"}
|  |A1A1 |A1A2 |A2A2|
|----------:|:------------:|:------------:|:-------------:|
| Fitness:  |{$$}w_{11}{/$$}|{$$}w_{12}{/$$}|{$$}w_{22}{/$$}|
| Frequency at generation t:  |{$$}p^2{/$$}|{$$}2pq{/$$}|{$$}q^2{/$$}|

Given these fitness values, and the frequencies in the current generation t, what are the genotype frequencies in the next generation t+1? Here they are:

{width="wide"}
|  |A1A1 |A1A2 |A2A2|
|----------:|:------------:|:------------:|:-------------:|
| Fitness:  |{$$}w_{11}{/$$}|{$$}w_{12}{/$$}|{$$}w_{22}{/$$}|
| Frequency at generation t:  |{$$}p^2{/$$}|{$$}2pq{/$$}|{$$}q^2{/$$}|
| Frequency at generation t+1:  |{$$}p^{2}w_{11}/\bar{w}{/$$}|{$$}2pqw_{12}/\bar{w}{/$$}|{$$}q^{2}w_{22}/\bar{w}{/$$}|

where {$$}\bar{w}{/$$} is the average fitness in the population, which can be calculated as 

{$$}
\bar{w} = p^{2}w_{11} + 2pqw_{12} + q^{2}w_{22}
{/$$} 

These few formulas form the basis for a lot that we will be doing in this chapter, so I want to make sure that we understand them well. Let’s go through an example with actual numbers.

Assume the genotype frequencies are 20%, 50% and 30% for genotypes A1A1, A1A2, A2A2, respectively. In other words, *p^2^ = 0.2*, *2pq = 0.5*, and *q^2^ = 0.3*. Let’s also assume that the fitness values of the three genotypes are {$$}w_{11} = 1{/$$}, {$$}w_{12} = 1.2{/$$}, and {$$}w_{22} = 1.5{/$$}. That is, A2A2 has the highest fitness, A1A2 has the second highest fitness, and A1A1 has the lowest fitness.

Now, if we would simply multiply the fitness values with the frequencies, we would get the following frequencies:

{$$}
p^{2}w_{11} = 1 * 0.2 = 0.2
{/$$}

{$$}
2pqw_{12} = 1.12 * 0.5 = 0.6
{/$$}

{$$}
q^{2}w_{22} = 1.5 * 0.3 = 0.45
{/$$}

The problem is that these new genotype frequencies (0.2, 0.6, and 0.45) don’t add up to 1, but of course they have to. So what we need to do is to normalize these values, so that they do indeed add up to 1 again. Normalizing here means to reduce each of the values by the same factor in such a way that the numbers add up to 1. It’s very easy to do that: simply add the three numbers up (0.2 + 0.6 + 0.45 = 1.25), and then divide each of the three numbers by that sum. We call the sum of the three numbers the average fitness in the population, {$$}\bar{w}{/$$}, and we get the normalized frequencies by dividing by it:

{$$}
\frac{p^{2}w_{11}}{\bar{w}} = \frac{0.2}{1.25} = 0.16
{/$$}

{$$}
\frac{2pqw_{12}}{\bar{w}} = \frac{0.6}{1.25} = 0.48
{/$$}

{$$}
\frac{q^{2}w_{22}}{\bar{w}} = \frac{0.45}{1.25} = 0.36
{/$$}

These numbers were rounded a bit - but I hope you get the idea. So overall, here is our example, in numbers:

{width="wide"}
|  |A1A1 |A1A2 |A2A2|
|----------:|:------------:|:------------:|:-------------:|
| Fitness:  |1|1.2|1.5|
| Frequency at generation t:  |0.2|0.5|0.3|
| Frequency at generation t+1:  |0.16|0.48|0.36|

This is quite interesting. As you can see, the frequency of the A1A1 genotype has gone down. That happened because it had the lowest fitness, relative to the others. However, the frequency of genotype A1A2 has also gone down. The only genotype that has not gone down in frequency is genotype A2A2 - indeed, its frequency has gone up.

It’s important to note that the absolute fitness values don’t matter. Instead of 1, 1.2 and 1.5, we could have chosen 10, 12, and 15, and we would have obtained the exact same results. What matters is only how the fitness values compare to each other - that is, their relative value.

What would happen if all three fitness values were exactly the same? (Think about this before reading on.) Recall that the average fitness is 

{$$}
\bar{w} = p^{2}w_{11} + 2pqw_{12} + q^{2}w_{22}
{/$$} 

If {$$}w_{11} = w_{12} = w_{22}{/$$} then

{$$}
\bar{w} = p^{2}w_{11} + 2pqw_{11} + q^{2}w_{11}
{/$$} 

from which we can factor out {$$}w_{11}{/$$} and obtain

{$$}
\bar{w} = w_{11}(p^2 + 2pq + q^2)
{/$$} 

Since {$$}p^2 + 2pq + q^2 = 1{/$$}, we get

{$$}
\bar{w} = w_{11}
{/$$} 


Thus, our next generation table will be:

{width="wide"}
|  |A1A1 |A1A2 |A2A2|
|----------:|:------------:|:------------:|:-------------:|
| Fitness:  |{$$}w_{11}{/$$}|{$$}w_{11}{/$$}|{$$}w_{11}{/$$}|
| Frequency at generation t:  |{$$}p^2{/$$}|{$$}2pq{/$$}|{$$}q^2{/$$}|
| Frequency at generation t+1:  |{$$}p^{2}w_{11}/w_{11} = p^{2}{/$$}|{$$}2pqw_{11}/w_{11} = 2pq{/$$}|{$$}q^{2}w_{11}/w_{11} = q^{2}{/$$}|

Our frequencies don’t change at all! Since all genotypes have the same fitness, there is no natural selection - and we are back in the Hardy-Weinberg world. This is an important insight - in order to have evolution by natural selection, there needs to be something for natural selection to act on. That something is a difference in fitness, or *variance in fitness*.

Given the three fitness values {$$}w_{11}{/$$}, {$$}w_{12}{/$$}, and {$$}w_{22}{/$$}, under what circumstances will an allele increase or decrease in frequency? Because we know what genotype frequencies are at generation *t+1*, we can easily calculate the frequency of allele A1 at that generation:

{$$}
p’ = \frac{p^{2}w_{11}}{\bar{w}} + \frac{2pqw_{12}}{2\bar{w}}
{/$$}

which is simply adding the frequency of genotype A1A1 to half of the genotype frequency of A1A2. We can simplify this a bit by removing the 2's on the right hand side of the equation:

{$$}
p’ = \frac{p^{2}w_{11}}{\bar{w}} + \frac{pqw_{12}}{\bar{w}}
{/$$}

which can be rewritten as

{$$}
p’ = \frac{p^{2}w_{11} + pqw_{12}}{\bar{w}}
{/$$}

The difference per generation is simply what we have at generation *t+1*, minus what we had at generation *t*:

{$$}
\Delta p = p’ - p
{/$$}

Having just established the equation for *p’*, we can rewrite this to get

{$$}
\Delta p = \frac{p^{2}w_{11} + pqw_{12}}{\bar{w}} - p
{/$$}

If we replace {$$}\bar{w}{/$$} with {$$}p^{2}w_{11} + 2pqw_{12} + q^{2}w_{22}{/$$}, we will get quite a beast of an equation, which can be simplified to this equation: 

{$$}
\Delta p = \frac{pq ( p (w_{11}-w_{12}) + q (w_{12}-w_{22}))} {p^{2}w_{11} + 2pqw_{12} + q^{2}w_{22}}
{/$$}

Now, I am the first to grant you that this is not a very memorable equation. However, it is the fundamental equation of evolution by natural selection. What it describes is the change in allele frequency, given the current allele frequencies, and the three fitness values. As we will see soon, this equation can explain a whole range of interesting phenomena.

If {$$}\Delta p{/$$} is positive, the allele will increase in frequency. If {$$}\Delta p{/$$} is negative, the allele will decrease in frequency. Note that in this world of an infinite population size, there is no randomness anymore - everything is determined. That’s why these models are called *deterministic* models (as opposed to the stochastic models that we worked with in some of the chapters above, where randomness played a big role).

Now you may think "fine - if an allele has a high fitness, it will increase in frequency; if it has a low fitness, it will decrease in frequency. So far so good. But is that all there is? Because it sounds almost too simple".

Half of the answer is yes - natural selection really is quite simple. An allele can confer an advantage or a disadvantage to the individuals carrying the allele. If it is an advantage, then on average, these individuals will survive better, and reproduce more, than the individuals without that allele. Because of genetic inheritance (offspring have the genes of their parents), that allele will become more frequent in the population, eventually being the only allele in the population. This is evolution by natural selection.

The other half of the answer is no - there is one aspect that is incredibly important when thinking about natural selection. That aspect is that fitness must be assigned to a genotype, not to an allele. Each diploid individual has two alleles, and in the case where we have two different alleles, there are three different genotypes: A1A1, A1A2, and A2A2. The different genotypes may have different fitness values. Sometimes, the two ways of assigning fitness (either to the allele or to the genotype) are equivalent. For example, if A1A1 has the lowest fitness, A1A2 has a higher fitness than A1A1, and A2A2 has the highest fitness of them all, then you might as well say that the allele A2 confers a fitness benefit: the more A2s you have, so to speak, the fitter you are:

{$$}
w_{11} < w_{12} < w_{22} 
{/$$}

In that case, natural selection is very easy to predict: the allele A2 will spread in the population. However, there are two cases where things are more interesting. The first case is when the fitness of the A1A2 genotype is higher than the other two fitnesses. The second case is when the fitness of the A1A2 genotype is lower than the other two fitnesses.

Let us find a good way to formalize these three cases. First, we start by arbitrarily setting the fitness value of A1A1 to 1. As we have seen before, the absolute values of fitness don’t matter - what matters is the relative fitness values, i.e. how they compare to each other. Thus, we can reduce the complexity of the system by simply setting one of them to a fixed value. The question is now, how do the other two fitness values compare to 1?

Let’s simplify this a bit further and say that no matter what, we assume that the A2A2 fitness is lower than 1, i.e. the genotype A2A2 is always less fit than the genotype A1A1. We could of course also assume that it is always higher, but you might as well just replace A1 with A2, and you would get the same system. It really doesn’t matter in this simple model: we are simply saying that one of the homozygotes has fitness 1, and that the other homozygote has a fitness that is lower than 1. It’s up to you to decide which of the homozygotes is the one with fitness 1. For the purpose of our discussion here, I’m setting A1A1 to be the genotype with fitness value 1, and A2A2 to be the genotype with the lower fitness.

But lower by how much? For this, let’s introduce a new, important parameter: the *selection coefficient, s*. This coefficient defines by how much the fitness of A2A2 is reduced, compared to the fitness of A1A1. In mathematical terms, {$$}w_{22} = 1-s{/$$}.

What about the fitness of the heterozygote, A1A2? That is where things get interesting. To capture the fitness for A1A2, we will now introduce another new parameter: the *heterozygous effect, h*. We simply define the fitness of A1A2 to be {$$}w_{22} = 1-hs{/$$}. Depending on the value of *h*, we can get all three different types of selection. Let me visualize this so that it becomes easier to understand.

First, our new fitness table is as follows:

{width="wide"}
|  |A1A1 |A1A2 |A2A2|
|----------:|:------------:|:------------:|:-------------:|
| Fitness:  |{$$}1{/$$}|{$$}1-hs{/$$}|{$$}1-s{/$$}|

As you can see, we now need to work with only two values (*h* and *s*), rather than with three ({$$}w_{11}{/$$}, {$$}w_{12}{/$$} and {$$}w_{22}{/$$}). The first effect of that reduction in parameters is that it makes our equation for {$$}\Delta p{/$$} a little simpler:

{$$}
\Delta p = \frac{pqs ( ph + q (1-h))}{(1 - 2pqhs - q2s)}
{/$$}

If we would plot the genotypes fitnesses visually, we would get one of the following graphs:

{width=50%}
![](images/ch_6_fitness_landscapes.png)

Any line in the green area, where *h* is some value between 0 and 1 (including 0 and 1), represents the case where the fitness of the heterozygote is an intermediate value between the fitness of the two homozygotes, or equal to one of them (think *fitness slope*). This type of selection is called *directional selection*.

The blue line, or really any line you can think of above the green area, represents the case where the fitness of the heterozygote is higher than the fitness of both homozygotes (think *fitness peak*). This type of selection is called *balancing selection*.

The red line, or really any line you can think of below the green area, represents the case where the fitness of the heterozygote is lower than the fitness of both homozygotes (think *fitness valley*). This type of selection is called *disruptive selection*.

As we’ll see below, these three types of fitness “landscapes” have very different dynamics. 


##Directional Selection

Let’s start with directional selection. Let’s go ahead and plot {$$}\Delta p{/$$}, the change in the frequency of allele A1, as a function of *p* (i.e. the allele's current frequency). We’ve used very similar code before, and we're also reusing our `draw_line_chart()` function for the plotting. All that needs to be implemented here is the actual equation:

~~~~~~~~
var s = 0.1;
var h = 0.2;

var data=[];
var x_max = 1;

for (var i = 0; i <= x_max + 0.005; i = i + 0.01) {
    var p = i;
    var q = 1-p;
    var delta_p = (p*q*s * ( p*h + q*(1-h))) / (1 - 2*p*q*h*s -q*2*s);
    data.push(delta_p);
}

draw_line_chart(data,"p","\u0394 p",[],x_max,true);
~~~~~~~~

(Note that '\u0394' stands for {$$}\Delta{/$$}). 

I> You may have noticed that I have passed a sixth parameter to the function `draw_line_chart()`. As indicated in chapter 3 where I introduced it, the function has been defined with 6 arguments. I simply never supplied values for all 6 arguments, until now. If a value is not supplied for an argument, the corresponding local variable in the function will be `undefined`. Thankfully, the function has always been able to deal with this situation.
I> 
I> So what is this argument for? The argument name for the parameter in the function is called `y_max_flex` - if it is not `true` (which is the case if you don't pass 6 values to the function in the first place), then the y axis will span from 0 to 1 (check some of the earlier figures that we generated with this function to verify that this is indeed the case). On the other hand, if it is `true`, the y axis will span from 0 to a little bit more than the maximum value in the data set - making sure that the entire vertical space in the figure is utilized.

Setting the values `s` and `h` to `0.1` and `0.2`, respectively, we get the following plot:

{width=90%}
![](images/ch_6_directional_selection_deltap_vs_p.png)

Let’s examine this plot. The first, and most important thing to notice is that {$$}\Delta p{/$$} is always positive (except when *p* is either 0 or 1). What that means for the allele A1 is that unless it is lost (i.e. *p = 0*) or fixed (i.e. *p = 1*), its frequency is going to be higher in the next generation. This is why this type of selection is called directional selection: the allele frequency knows only one direction, and that is up in this case. The A1 allele will go to fixation.

The second thing to notice is that {$$}\Delta p{/$$} is largest around *p = 0.35*. In other words, when the frequency of the allele A1 is around one third, the per generation increase will be maximal. To understand this a little better, let’s go ahead an run a (deterministic) simulation, starting a `p = 0.01`.

I’m going to be using the following code:

~~~~~~~~
var s = 0.1;
var h = 0.2;
var p = 0.01;

var data=[];
var generations = 400;

for (var i = 0; i < generations; i = i + 1) {
    var q = 1-p;
    var delta_p = (p*q*s * ( p*h + q*(1-h))) / (1 - 2*p*q*h*s -q*2*s);
    p = p + delta_p;
    data.push(p);
}

draw_line_chart(data,"Generation","p",[],generations);
~~~~~~~~

This code is very similar to the one we used above. Given `s`, `h`, and `p`, we simply run a number of generations where we calculate {$$}\Delta p{/$$}, and then add that to the previous value of `p` in order to get the new value of `p`.

What we will see is the following plot:

{width=90%}
![](images/ch_6_directional_selection_p_vs_time.png)

As you can see, *p* starts increasing right from the start, even if a little slow. Then, around generation 25, when *p* is roughly 0.1, the increase starts accelerating noticeably. We know from the previous plot that the per generation increase is maximal at around *p = 0.35*, after which the increase starts slowing down again, leading to the classical observed S-shaped curve.

If you play around with the `s` and `h` values (making sure that they remain between 0 and 1), you will notice that the shapes of the curves will change a bit. Depending on the value of `s`, the fixation of the allele will be slower or faster. Depending on the value of `h`, the allele will increase rapidly in the beginning, and then slow down as it approaches fixation, or it will increase slowly in the beginning, and then rapidly go to fixation at the end. Nevertheless, the ultimate outcome is always the same - fixation. This is the consequence of directional selection.


##Balancing Selection

Let us now move on to the next type of selection: balancing selection. Recall that balancing selection means that the fitness of the heterozygote is higher than that of both homozygotes (resulting in the fitness peak in the fitness landscape figure above). In order to achieve that, we need to set the heterozygote effect, *h*, to a negative value.

We can reuse the code from above, and plot {$$}\Delta p{/$$} as a function of *p* with the values `s = 0.1` and `h = -0.5`. If we do that, we get the following plot:

{width=90%}
![](images/ch_6_balancing_selection_deltap_vs_p.png)

Interesting! As you can see, {$$}\Delta p{/$$} is mostly positive, but for values of *p* higher than 0.75, it starts to become negative. What does that mean for the evolutionary dynamics?

Let’s start again at a low *p* value, and use this plot to understand what will happen. Let’s say we start at a low *p* value, where {$$}\Delta p{/$$} is positive. A positive {$$}\Delta p{/$$} means that *p* is going to be even higher in the next generation. We’ll keep on moving to the right on the x axis, to higher values of *p*, until we get to the point where {$$}\Delta p{/$$} is zero (at *p = 0.75*). What happens then? Nothing, really - the allele frequency has arrived at an equilibrium.

Imagine now for a moment that some event will bump *p* up to 0.9. At this value, {$$}\Delta p{/$$} is negative, which means that *p* will be lower in the next generation. If we follow the same procedure, we’ll keep on moving to the left on the x axis, to lower values of *p*, until we once again get to the point where {$$}\Delta p{/$$} is zero.

In other words, *p = 0.75* is a stable equilibrium. If the *p* value is somehow reduced, it will go right back up to 0.75. If it is somehow increased, it will go right back down to 0.75.

This is an intriguing finding. It means that the allele A1 will *not* go to fixation, even though the genotypes A1A1 and A1A2 have higher fitness values than A2A2. What is going on here? Well, it is true that the fitness of A1A1 is higher than the fitness of A2A2. However, the heterozygote A1A2 has the highest fitness. This will keep the A2 allele around, and is the reason why A1 won’t go to fixation.

Another way to think about this is to imagine that your entire population is A1A1. Now, imagine that you introduce an A1A2 genotype. Because this heterozygote has a higher fitness than the other A1A1 genotypes, it will increase in frequency, and thus the A2 allele will increase in frequency too (and the A1 frequency will decrease). However, this process can’t go on forever, because A1A2 genotypes will produce both A1A1 and A2A2 offspring genotypes, which have lower fitness values.

Let’s see if our reasoning is correct, and plot the result of a deterministic simulation, using a slightly adapted version of our previous code, with `s = 0.1` and `h = -0.5`. This time, however, we run multiple simulations, starting at `p = 0.01` all the way up to `p = 0.99`, in `0.01` increments. We can adapt the code like so:

~~~~~~~~
var s = 0.1;
var h = -0.5;
var initial_p = 0.01;
var p_values = [];

var data = [];
var generations = 300;

while (initial_p < 1) {
    p_values.push(initial_p);
    initial_p = initial_p + 0.01;
}

for (var i = 0; i < p_values.length; i = i + 1) {
    run_simulation(p_values[i]);
}

function run_simulation(p) {
    var results = [];
    for (var i = 0; i < generations; i = i + 1) {
        var q = 1-p;
        var delta_p = (p*q*s * ( p*h + q*(1-h))) / (1 - 2*p*q*h*s -q*2*s);
        p = p + delta_p;
        results.push(p);
    }
    data.push(results);
}

draw_line_chart(data,"Generation","p",[],generations);
~~~~~~~~

This code makes use of the same concepts that we used in chapter 3, where we plotted multiple simulation runs at the same time. Since it’s been a while since that chapter, let’s revisit what’s going here. The key idea is that rather than storing the resulting values of a single simulation run in one array, we now have to store multiple such arrays in another array (i.e. a two-dimensional array). I’ve encapsulated the actual simulation code in a function `run_simulation()`, to which I’m passing an initial value for `p`. For each simulation, I’m creating a new `results` array, in which I will store the results of this particular simulation run. Once the simulation has run its course, I store the `results` array in the `data` array. It is this two-dimensional `data` array that I’m passing on to the plotting function.

Because I have numerous initial values of `p`, I will store all of them in an array called `p_values`. I’ve already set the first initial value of `p`, `initial_p`, to `0.01`. Starting from that, I then create all the other initial values for `p` and store them in the array with this snippet of code:

~~~~~~~~
while (initial_p < 1) {
    p_values.push(initial_p);
    initial_p = initial_p + 0.01;
}
~~~~~~~~

This is a new loop construct that we haven’t met before. We’ve met the `for` loop, and the `do while` loop. The `while` loop is a simplified version of the `do while` loop. The `do while` loop, as you may recall, executes some code at least once, and then repeats executing it while a given condition is true. The `while` loop simply executes some code while a given condition is true. It may be that the condition is false already from the get go, and the code would never be executed. 

For our purpose here, the `while` loop is sufficient. It fills up the `p_values` array with values starting at `0.01`, up to `0.99`, in `0.01` increments. Once the array with initial values for `p` is set up, we simply iterate over it and call the `run_simulation()` function, passing along the corresponding initial value of `p`.

This produces the following plot:

{width=90%}
![](images/ch_6_balancing_selection_p_vs_time.png)

As this plot clearly shows, all simulation runs will go the equilibrium allele frequency of *p = 0.75*, independent of the initial value of p. Thus, our reasoning was correct.

You probably understand now why this type of selection is called balancing selection. It balances the allele frequencies at an equilibrium value, because both homozygotes are less fit than the heterozygote. Balancing selection is important because it maintains genetic variation. As we’ve seen above, that’s not true with directional selection, which will get rid of genetic variation.

There’s one more thing about balancing selection that I want to mention. It turns out that to you can very easily calculate the equilibrium frequency under balancing selection. It is simply

{$$}
p* = \frac{h-1}{2h-1}
{/$$}

In our code above, we used `h = -0.5`. And if you plug *h = -0.5* into the equation above, you'll get {$$}p* = 0.75{/$$}. It’s also interesting to note that the equilibrium value does not depend on the selection coefficient, *s*. A higher selection coefficient will lead to faster dynamics, i.e. the population will reach the equilibrium value of *p* faster - but it will still be the same value. You can experiment with the value of `s` in your code to verify this.


##Disruptive Selection

Last, but certainly not least, let’s take a look at disruptive selection. Disruptive selection occurs when the fitness value of the heterozygote genotype A1A2 is lower than that of both homozygotes (resulting in the fitness valley in the figure above). Disruptive selection occurs when the value of the heterozygote effect, *h*, is larger than 1.

As before, let’s go ahead and plot the value {$$}\Delta p{/$$} as a function of *p*, but this time with the values `s = 0.1` and `h = 1.5`. This gives us the following plot:

{width=90%}
![](images/ch_6_disruptive_selection_deltap_vs_p.png)

This plot looks rather similar to the plot that we saw in the case of balancing selection above. For most of *p*, {$$}\Delta p{/$$} is positive, but sometimes, it is negative. The only difference here is that the negative values of {$$}\Delta p{/$$} are found of the left side of the graph, where *p* is small.

Let’s follow our method again and start with a low value of *p*, and see where this takes us. With a low value of *p*, {$$}\Delta p{/$$} is negative, which means that *p* will be even lower in the next generation. Because {$$}\Delta p{/$$} will again be negative (and remain there until *p = 0*), *p* will go down to 0, and the A1 allele will be lost.

Now let’s start with a higher value for *p*, for example *p = 0.5*. At that value, {$$}\Delta p{/$$} is positive, which means that *p* will be higher in the next generation. Because {$$}\Delta p{/$$} will again be positive (and remain there until *p = 1*), *p* will go all the way up to 1, and the A1 allele will be fixed.

This is another astounding finding. It turns out that in the case of disruptive selection, evolutionary dynamics can go either way - the A1 allele can either go to fixation, or it can be lost altogether! It all depends on the initial conditions - i.e. the initial value of *p*. This is quite remarkable, and somehow violates our intuition. Shouldn’t a deterministic system always go to the same equilibrium value?

The answer to this question is no. Some systems have multiple equilibria. The system of disruptive selection, it turns out, has three such equilibria. Why three? Let’s go ahead an run a few simulations, plotting the evolutionary dynamics of disruptive selection. We can reuse the code from above, and simply set the heterozygous effect, `h`, to `1.5`. Here’s what we’ll find:

{width=90%}
![](images/ch_6_disruptive_selection_p_vs_time.png)

As predicted, depending on the initial conditions, *p* will either go to 0 or to 1. These are two of there three equilibria. However, there seems to be another equilibria at *p = 0.25*. What’s up with that?

If we revisit the plot above, we can see that when *p = 0.25*, {$$}\Delta p{/$$} is 0. That is why *p = 0.25* is an equilibrium; the value of *p* won’t change. However, there is something special about this equilibrium. Let’s say your population is exactly at *p = 0.25*. Now assume that for some reason, the value of *p* is pushed very slightly upward. Now, {$$}\Delta p > 0{/$$}, and the allele will go to fixation. On the other hand, if you assume that the value of *p* is pushed very slightly downward, to a value that is less than 0.25, you’ll find that {$$}\Delta p < 0{/$$}, and the allele will start its downward path until it is lost from the population. In other words, *p = 0.25* is not a stable equilibrium. Quite the opposite - it is a so-called *unstable* equilibrium. An unstable equilibrium is an equilibrium where, if even just slightly pushed away from the equilibrium value, the system will go to another equilibrium value (0 or 1 in this case).

Thus, the unstable equilibrium is not important with respect to the population remaining there - it won’t. Even if it happens to be there for a moment, the slightest deviation from that value will make the system go to one of the other two states. We can demonstrate this using our code, simply by changing this line in the `while` loop:

~~~~~~~~
initial_p = initial_p + 0.01;
~~~~~~~~

to this

~~~~~~~~
initial_p = initial_p + 0.01 + (Math.random() * 0.000001);
~~~~~~~~

What we are doing here is to add a tiny value (between 0 and a millionth) to the initial value of `p`. If you now rerun the code, you will see the following:

{width=90%}
![](images/ch_6_disruptive_selection_p_vs_time_v2.png)

As you can see, the purple line will not remain at its initial value anymore. It will, as predicted, increase in frequency and go to fixation. Initially, the values of {$$}\Delta p{/$$} are very, very small in the vicinity of *p = 0.25*, which is why it takes quite some time for the line to visibly begin its upward trajectory.

It is nevertheless important to know this equilibrium value, because of its importance in predicting the dynamics of the system. Once again, it turns out that it’s very easy to calculate this value. Indeed, it is the exact same value as in the case of balancing selection:

{$$}
p* = \frac{h-1}{2h-1}
{/$$}

The crucial difference is that in the case of balancing selection, the system will converge to {$$}p*{/$$}, while in the case of disruptive selection, the system will go away from {$$}p*{/$$}, to either 0 or 1. And once again, the value of the selection coefficient, *s*, has no effect on this value. It will simply determine at what speed the system will find its stable equilibrium.

To sum up - evolution by natural selection, even in a simple model of one gene with two alleles, can result in very different dynamics, depending on the fitness landscape. In the case of directional selection, the same allele will always go to fixation. In the case of balancing selection, both alleles will always remain in the population at an equilibrium. In the case of disruptive selection, one of the alleles will go to fixation, but which one will depend on the initial conditions.


##Coevolution

You now understand how evolution by natural selection works. Genotypes with higher fitness have a higher probability of surviving and reproducing, and thus a higher chance of passing on their alleles to the next generation. Over the generations, those alleles and genotypes become more frequent.

We’ve haven’t talked much about fitness until now. We simply mentioned earlier that fitness is the ability to survive and reproduce. But why are certain genotypes better able to survive and reproduce? Let’s think about some examples. An animal may survive better because it is harder to be spotted by a predator. Another animal may survive better because it has better senses to locate its prey. Another animal may survive better because it can deal with harsher climates. What all of these examples have in common is that the animals are simply better adapted to their current environment. It is the natural environment that is doing the selecting - hence the term natural selection (as opposed to artificial selection in animal and plant breeding, for example).

We have seen above that interesting dynamics can result from this simple logic. But things get even more interesting when the environment is not just the abiotic (non-living) environment (such as the climate), but rather the biotic environment - in particular when the environment consists of other species who are subject to natural selection themselves. When the fitness of one species depends on the fitness of another species, co-evolution is often a direct consequence.

A good example of co-evolution is the interaction between hosts and parasites. A parasite has a high fitness if it can infect a host, evade the host’s immune responses (i.e. survive), and create many offspring parasites. The problem is that the host’s fitness will be reduced by the success of the parasite: many parasitic infections make a host sick, reducing the host's ability to survive and reproduce. Thus, hosts that can avoid or kill off parasites without getting sick have a higher fitness than those who can’t. In other words, natural selection will favor those hosts that can avoid getting infected. In turn, the parasites that can’t infect a host will have a very low fitness, and natural selection will favor those parasites that find new ways to infect the hosts. Thus, an endless coevolutionary arms race begins, where the host tries to build defense systems against parasite infection, and the parasites try to find ways around the defense systems. Both species are playing catch up all the time, which can lead to very interesting evolutionary dynamics.

In this section, we will build a simple coevolutionary arms race between a host and a parasite species. We will do this by implementing a simple conceptual model of genetic interactions between hosts and parasites. We are going to assume that the host has one gene with two alleles (A1 and A2) that represent a simple immune system. Equally, we are going to assume that the parasite has a gene with two alleles, A1 and A2. To keep things simple, we will assume haploid hosts and parasites - that is, both hosts and parasites have only one allele, not two. Thus, there are only two possible genotypes, A1 and A2, and we can use the term allele and genotype interchangeably.

You can think of the genetic host-parasite interaction system as a key-lock mechanism: in order to get into the host, the parasite allele (the key) needs to match the host’s allele (the lock).

In reality, the genetics of parasites and hosts are much more complicated, but this simple system captures a key idea. That key idea is *negative frequency-dependent selection*. This is quite a mouthful, but it is actually a rather easy idea to grasp. Frequency-dependent selection simply means that an individual’s fitness value does not only depend on its genotype, but also on the *frequency* of its genotype in a population. This can work in two ways:

1. A genotype could be more fit when it is more common in the population (this is called *positive* frequency-dependent selection).

2. A genotype could be less fit when it is more common (this is called *negative* frequency-dependent selection).

Negative frequency-dependent selection is much more common in nature than positive frequency-dependent selection. Almost all antagonistic species interactions such as host-parasite or predator-pray interactions result in negative frequency-dependent selection. The key-lock model above is a great example. Imagine that almost every host has the lock A1. Because only parasites with the key A1 can infect those hosts, there is a huge selective benefits for A1 parasites, and they will increase rapidly in frequency. However, that means that there are increasingly fewer parasites with the (non-matching) A2 keys. This in turn means that the hosts with the A2 locks are becoming less infected. In this case, the A2 host genotype benefited from being rare, because the parasite population adapted to attack the very frequent A1 host genotype.

However, this blissful safety that the A2 hosts enjoy is only of limited duration. Because A2 hosts get less often infected, they are at a selective advantage, and will thus increase in frequency. As they increase in frequency, the parasite population will catch up on them, driven by natural selection. As you can guess, this leads to a never ending cycling of genotypes, where the hosts try to escape the parasites (genetically speaking), and the parasites try to catch up with the hosts. This type of dynamic is often called “Red Queen” dynamic, inspired by the fictitious character of the Red Queen in Lewis Carroll's famous book ‘Through the Looking-Glass’, who at one point in the story explains: “Now, here, you see, it takes all the running you can do, to keep in the same place!”.

Let’s go ahead and implement this simple host-parasite model, and see if we really get those cyclical dynamics!

The first thing we’re going to do is set up a few key variables:

~~~~~~~~
var data = [];
var generations = 400;

var host_frequencies = [0,0];
var parasite_frequencies = [0,0];

var sh = 0.2;
var sp = 0.5;
~~~~~~~~

The `data` array, as always, will store the data that we want to plot, i.e. the host and parasite genotype frequencies. The `generations` variable defines the duration of the simulation, expressed as the number of generations. The two arrays `host_frequencies` and `parasite_frequencies` will keep track of the frequencies of the two genotypes in each species throughout the simulation. We initialize the values at `0`, but we’ll change that in a minute. Note that both arrays have two elements, since there are only two possible genotypes in each of the haploid species (A1 and A2). 

Finally, the last two variables, `sh` and `sp`, define the fitness reduction (selection coefficient *s*) if the host gets infected by a a parasite, or if the parasite cannot infect a host, respectively. 

There are four combinations of possible interactions between the two host and parasite genotypes, with the following outcomes:

{width=75%}
![](images/ch_6_host_parasite_matrix.png)

We will implement this fitness model in a minute. The important thing to note is that if the genotypes don’t match, the parasite won’t be able to infect the host. That’s great for the host, who will have the maximal fitness value `1`. It’s bad for the parasite though, as parasites generally need a host to reproduce. The parasite’s fitness value is reduced by the parasite-specific selection coefficient `sp`, to `1-sp`. On the other hand, if the genotypes do match, the parasite will be able to infect the host. In this case, the parasite’s fitness is maximal (i.e. `1`), and the host’s fitness is reduced by the host-specific selection coefficient `sh`, to `1-sh`, due to the infection.

To start the simulation, let’s initiate the genotype frequencies and push to the `data` array accordingly:

~~~~~~~~
function initialize_frequencies() {
    host_frequencies[0] = Math.random();
    data.push([host_frequencies[0]]);
    host_frequencies[1] = 1 - host_frequencies[0];
    data.push([host_frequencies[1]]);
    parasite_frequencies[0] = Math.random();
    data.push([parasite_frequencies[0]]);
    parasite_frequencies[1] = 1 - parasite_frequencies[0];
    data.push([parasite_frequencies[1]]);
}

initialize_frequencies();
~~~~~~~~

The first line in this method sets the first element of the `host_frequencies` array (which holds the frequency of host genotype A1) to a random number between 0 and 1. The second line adds an array to the the `data` array, initialized with a single value - that of the host genotype A1 frequency which we have just set. 

Keep in mind that our `data` array will end up being a two-dimensional array, which holds the four arrays storing the four genotype frequencies over the generations. Because the data array is initially empty, the line 

~~~~~~~~
data.push([]);
~~~~~~~~

would simply add an empty array `[]` to the `data` array, making it an empty two-dimensional array. Instead of pushing an empty array, we can push an array that has values in it already. For example, we could write

~~~~~~~~
data.push([1,4,7]);
~~~~~~~~

In this case, we would now have a two-dimensional array where the first element of `data` (i.e. `data[0]`), would contain the array `[1,4,7]`. Our actual code reads

~~~~~~~~
data.push([host_frequencies[0]]);
~~~~~~~~

which means that the first element in `data` is now an array with one value, namely the host genotype A1 frequency, `host_frequencies[0]`.

The next two lines are similar:

~~~~~~~~
host_frequencies[1] = 1 - host_frequencies[0];
data.push([host_frequencies[1]]);
~~~~~~~~

In the first line, we simply set the frequency of host genotype A2, which is 1 minus the frequency of host genotype A1 (since they must add up to 1). The second line pushes another, new array into `data`, this time with the initial frequency of the host genotype A2.

The following four lines are more or less identical, simply setting the parasite frequencies in the exact same manner. After this function has finished executing, we have all initial four genotype frequencies set to random values, and our data array is initialized with the four arrays keeping track of the four genotype frequencies over time, and the first value in each array is already set. We’re good to move on!

After calling the function `initialize_frequencies()`, we we will run the following code:

~~~~~~~~
for (var i = 0; i < generations; i = i + 1) {
    host_selection();
    parasite_selection();
    data[0].push(host_frequencies[0]);
    data[1].push(host_frequencies[1]);
    data[2].push(parasite_frequencies[0]);
    data[3].push(parasite_frequencies[1]);
}
draw_line_chart(data,"p","Generation",[]);
~~~~~~~~

This loop runs over a given number of generations, and in each generation, calls the two methods `host_selection()` and `parasite_selection()`. These methods will calculate the new genotype frequencies, based on the current genotype frequencies and the fitness values. We’ll implement them right away. Once they have finished executing, we will store the new genotype frequencies in the corresponding array in `data`. And finally, after the generations have passed, we'll plot the results stored in `data` visually.

Let’s now turn to the key methods in our simulation, `host_selection()` and `parasite_selection()`. Before we develop the code, let’s think about how they should work. 

At the beginning of this chapter, we calculated frequencies of alleles over time, given certain fitness values of genotypes. These fitness values were assumed to be constant. Then, we simply developed the following logic for a given genotype: The frequency of a genotype at time *t+1*, {$$}f_{t+1}{/$$}, equals its frequency at *t*, {$$}f_{t}{/$$}, times its fitness value, *w*, normalized by the total population fitness, {$$}\bar{w}{/$$}. In mathematical terms, we had

{$$}f_{t+1} = \frac{wf_{t}}{\bar{w}}{/$$}

The same logic applies in frequency dependent selection, with one important difference: the fitness value *w* is not a constant anymore, but rather a function of other genotype frequencies. In our case, the fitness of a given host genotype depends on the parasite frequencies.

As a concrete example, the fitness of host genotype A1, {$$}w_{H1}{/$$}, depends on both parasite frequencies {$$}f_{P1}{/$$} and {$$}f_{P2}{/$$}, as well as the fitness values for host A1 when interacting with parasite A1 ({$$}w_{H1P1}{/$$}), and when interacting with parasite A2 ({$$}w_{H1P2}{/$$}):

{$$}
w_{H1} = w_{H1P1}f_{P1} + w_{H1P2}f_{P2}
{/$$}

Think about it as follows. As a host with genotype A1, you can either meet a parasite with genotype A1 (which will happen with probability {$$}f_{P1}{/$$}, the frequency of parasite genotype A1), or you can meet a parasite with genotype A2 (which will happen with probability {$$}f_{P2}{/$$}, the frequency of parasite genotype A2). In the first case, the fitness of the host A1 when meeting parasite A1, {$$}w_{H1P1}{/$$}, will be *1-sh*. In the second case, the fitness of the host A1 when meeting parasite A2, {$$}w_{H1P2}{/$$}, will be 1. The total fitness is simply the sum of these two possible cases. The exact same logic applies for all the other genotypes.

Note that there is no normalizing happening at this stage, since we aren’t calculating frequencies yet. Now, if we want to know the frequency of host genotype A1 in the next generation, we will do the exact same thing as we have before: multiply its fitness, {$$}w_{H1}{/$$}, with its frequency. Then, we do the same thing for host genotype A2. Once we have these two frequencies, we need to normalize them by their sum, since they might add up to a value other than 1.

In code, this looks as follows:

~~~~~~~~
function host_selection() {
    var sum_host_frequencies = 0;
    for (var i = 0; i < host_frequencies.length; i = i + 1) {
        var current_host_fitness = 0;
        for (var ii = 0; ii < parasite_frequencies.length; ii = ii + 1) {
            current_host_fitness = current_host_fitness + get_host_fitness(i, ii);
        }
        host_frequencies[i] = host_frequencies[i] * current_host_fitness;
        sum_host_frequencies = sum_host_frequencies + host_frequencies[i];
    }
    for (i = 0; i < host_frequencies.length; i = i + 1) {
        host_frequencies[i] = host_frequencies[i] / sum_host_frequencies;
    }
}

function get_host_fitness(i,ii){
    return (i == ii ? 1-sh : 1) * parasite_frequencies[ii]
}
~~~~~~~~

Let’s walk through this line by line. At first, we initialized the variable `sum_host_frequencies` at 0. This variable will be necessary for the normalizing at the end. Then, in the first loop, we go through all host frequencies, and calculate their new frequencies, using the formula above.

Notice how the first four lines in that loop,

~~~~~~~~
var current_host_fitness = 0;
for (var ii = 0; ii < parasite_frequencies.length; ii = ii + 1) {
    current_host_fitness = current_host_fitness + get_host_fitness(i, ii);
}
~~~~~~~~

are the programmed equivalent of 

{$$}
w_{H1} = w_{H1P1}f_{P1} + w_{H1P2}f_{P2}
{/$$}

The function `get_host_fitness(i, ii)` simply returns the product of the frequency and the fitness:

~~~~~~~
function get_host_fitness(i,ii){
    return (i == ii ? 1-sh : 1) * parasite_frequencies[ii]
}
~~~~~~~

There is something interesting in that function that we haven’t seen before, which is this expression:

~~~~~~~
i == ii ? 1-sh : 1
~~~~~~~

This is the so-called *ternary* operator `?:` which is a short cut for an `if else` expression. It works as follows. The following `if else` expression

~~~~~~~
if (condition) {
   code1
}
else {
   code2
}
~~~~~~~

Can be simplified with the ternary operator `?:` as follows:

~~~~~~~
condition ? code1 : code2
~~~~~~~

Note that these two pieces of code do the exact same thing - they’re just different versions of expressing an idea. This is very common - there are infinitely many ways to achieve the same thing in code. Don’t worry if you would implement an idea differently than I have here throughout the book. As long as your code does the same thing, it’s perfectly fine. As you become more comfortable with programming, you will learn that some ways can be better than others to express the same idea - either because they’re easier to read, easier to extend, or for other reasons. At this stage in your path to learning programming, you don’t need to worry about this too much. Shorter code is not automatically better code. What is most important at the moment is that you understand what you’re doing, and that you will find it easy to read your code when you go back to it in the future.

Back to our function, where the next two lines read

~~~~~~~
host_frequencies[i] = host_frequencies[i] * current_host_fitness;
sum_host_frequencies = sum_host_frequencies + host_frequencies[i];
~~~~~~~

Now that we’ve calculated the current host fitness (given the parasite frequencies), we can multiply it with the current host frequency in order to get the new host frequency. Then, we add this value to `sum_host_frequencies` for later normalization.

After the loop has gone through all hosts genotypes, and calculated the new frequencies, we need to normalize them so that they add up to 1 again. The last three lines in the function take care of this:

~~~~~~~
for (i = 0; i < host_frequencies.length; i = i + 1) {
    host_frequencies[i] = host_frequencies[i] / sum_host_frequencies;
}
~~~~~~~

And that’s it. The function `parasite_selection()` follows the exact same logic, except that we now do everything from the perspective of the parasite:

~~~~~~~
function parasite_selection() {
    var sum_parasite_frequencies = 0;
    for (var i = 0; i < parasite_frequencies.length; i = i + 1) {
        var current_parasite_fitness = 0;
        for (var ii = 0; ii < host_frequencies.length; ii = ii + 1) {
            current_parasite_fitness = current_parasite_fitness + get_parasite_fitness(i, ii);
        }
        parasite_frequencies[i] = parasite_frequencies[i] * current_parasite_fitness;
        sum_parasite_frequencies = sum_parasite_frequencies + parasite_frequencies[i];
    }
    for (i = 0; i < parasite_frequencies.length; i = i + 1) {
        parasite_frequencies[i] = parasite_frequencies[i] / sum_parasite_frequencies;
    }
}

function get_parasite_fitness(i,ii) {
    return (i == ii ? 1 : 1-sp) * host_frequencies[ii]
}
~~~~~~~

And that’s it! Now that have put everything together, we can run the code and look at the output. Here’s what I see, the first time I run this code:

{width=90%}
![](images/ch_6_red_queen_400.png)

Wow - cyclical dynamics indeed! This is the Red Queen, in action.

Go ahead and reload the page a number of times. You will see that the dynamics are very much dependent on initial conditions. In addition, try changing the values of the selection coefficients `sh` and `sp`, and see how that changes the dynamics.

Before we conclude, I’d like to make one very small modification to the code. In your function `host_selection()`, go ahead and add this line

~~~~~~~
host_frequencies[i] = host_frequencies[i] + Math.random() * 0.01;
~~~~~~~

right after this one

~~~~~~~
host_frequencies[i] = host_frequencies[i] * current_host_fitness;
~~~~~~~

What the new line does is to add a very small value - a random number between 0 and 0.01 - to the new host frequencies. At this stage, the host frequencies are not yet normalized, so the net effect of this addition is that the normalized host frequencies will just be slightly disturbed.

Before you reload the page, set the number of generations to `2000` - you’ll see why in a second:

~~~~~~~
var generations = 2000;
~~~~~~~

Now reload the page. Here’s what I see the first time I run this code:

{width=90%}
![](images/ch_6_red_queen_2000.png)

Look at that - that’s a very different system from what we just observed. What is going on here?

It turns out that the very strong and regular cyclical dynamics are an artifact of a purely deterministic system. In our original code, everything was deterministic - there was no randomness to anything. As this small code change demonstrates, adding a little bit of randomness - or noise, if you will - to the host frequencies dramatically changes the dynamics of the system. In other words, the dynamics that we observed are not robust. When slightly perturbed, the system behaves very differently. 

Why does this matter from a biological perspective? By adding a little bit of noise to the host genotype frequencies, we’ve essentially introduced the effects of random genetic drift. It’s very reasonable to assume that host populations are not always extremely large, and that drift will therefore affect genotype frequencies. What this shows is that even a little bit of genetic drift will change the evolutionary dynamics considerably. We still get cycling dynamics, but they are much less pronounced than in the purely deterministic system. In addition, the dynamics seem to be more complex, with larger changes occurring over hundreds of generations (this is why I asked you to increase the number of generations to 2,000).

And with that, we conclude the chapter on natural selection. Natural selection is an enormously potent force, being responsible for all adaptations that we see in nature. As you can imagine, we have only scratched the surface here. But we have learned some key insights into how natural selection works, and how it can affect evolution.

Let’s briefly wrap up what we learned in this chapter.

* Genotypes and alleles that give individuals a higher average chance to survive and reproduce will over time increase in frequency - this process is called evolution by natural selection.
* Fitness is a measure of the ability to survive and reproduce.
* In diploid individuals, there are three possible types of natural selection: directional selection, balancing selection, and disruptive selection.
* Directional selection will drive alleles to fixation.
* Balancing selection will maintain genetic diversity in a population.
* Disruptive selection will drive alleles to fixation, but which ones depends on initial conditions.
* Negative frequency-dependent selection (coevolution) leads to cyclical evolutionary dynamics (red queen dynamics).
* Red queen dynamics can be strongly affected by genetic drift.
* We’ve also introduced the ternary operator in JavaScript.

We’ve now covered all four forces affecting evolution: drift, mutation, migration, and natural selection. You’ve come a long way. Not only do you now have an overview on the major forces affecting the living world, but you also have the ability to implement these ideas in code. This is a wonderful achievement - congratulations. In the next chapters, we’ll be looking at some other, highly interesting dynamic systems in biology: we’ll look at how infectious disease spread, and how cooperation evolves.

